# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N1RpsXwXumdBRrNiyWAy9FUmFpfISUVe
"""

!git clone https://github.com/YoongiKim/CIFAR-10-images

import torch
import numpy as np

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'

import matplotlib.pyplot as plt

import torch
from torchvision import datasets, transforms

import helper

!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py

import importlib
importlib.reload(helper)

train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')

import os
entries = os.listdir('CIFAR-10-images/train')

L=[]
for entry in entries:
  for i in os.listdir('CIFAR-10-images/train/'+str(entry)):
    L.append(['CIFAR-10-images/train/'+str(entry)+str(i),entry])

import pandas as pd
traindata=pd.DataFrame(L,columns=["location","class"])

traindata.to_csv("train",index=False)

testent=os.listdir('CIFAR-10-images/test')

L2=[]
for entry in testent:
  for i in os.listdir('CIFAR-10-images/test/'+str(entry)):
    L2.append(['CIFAR-10-images/test/'+str(entry)+str(i),entry])

testdata=pd.DataFrame(L2,columns=["location","class"])
testdata.to_csv("test",index=False)

import imageio
from torch.utils.data import Dataset as Dataset

class CifarDatasetT(Dataset):
    def __init__(self, train_images, transform=None):
        '''
        Args : 
            csvfile : train/val/test csvfiles
            audio_dir : directory that contains folders 0 - f
        '''
        self.train_images = train_images
        self.transform = transform

    # get one segment (==59049 samples) and its 50-d label
    def __getitem__(self, index):

      if self.transform:
        x = torch.tensor(self.transform(Image.fromarray(self.train_images[index][0]))).to(torch.float32).unsqueeze(0)
      else:
        x = torch.tensor(Image.fromarray(self.train_images[index][0])).to(torch.float32).unsqueeze(0)
      y = self.train_images[index][1]

      sample = {'image': x, 'class': y}

      # if self.transform:
      #   sample = self.transform(sample)


      return sample

        
    
    def __len__(self):
        return len(self.train_images)

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.c1 = nn.Conv2d(3, 16, 3, padding=1)
        self.c2 = nn.Conv2d(16, 32, 3, padding=1)
        self.c3 = nn.Conv2d(32, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 4 * 4, 500)
        self.fc2 = nn.Linear(500, 10)
        self.dropout = nn.Dropout(0.25)

    def forward(self, x):
        x = self.pool(F.relu(self.c1(x)))
        x = self.pool(F.relu(self.c2(x)))
        x = self.pool(F.relu(self.c3(x)))
        x = x.view(-1, 64 * 4 * 4)
        x = self.dropout(x)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

model = Net()
print(model)